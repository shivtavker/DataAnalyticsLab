{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1P3fTzt_wZ1"
   },
   "source": [
    "# Diabetes Data Set\n",
    "\n",
    "Dataset file: 'diabetes.data'  \n",
    "Reference link for description of dataset: https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwuU7CGN_wZ4"
   },
   "source": [
    "### Preview of the Data Set\n",
    "\n",
    "Load the data set.\n",
    "\n",
    "a) Analyse the data set. Print the number of features, feature names, data types of the features, number of data points and the values of the first 10 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43689,
     "status": "ok",
     "timestamp": 1565616556350,
     "user": {
      "displayName": "MALKAPURAM GANDLA SAI SREE",
      "photoUrl": "",
      "userId": "06629185457401699264"
     },
     "user_tz": -330
    },
    "id": "Xzaddo1IA7hv",
    "outputId": "96b5cb56-eb5b-4fcb-d768-e7a6e7533463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AGE  SEX   BMI      BP   S1     S2    S3    S4      S5   S6    Y\n",
      "0     59    2  32.1  101.00  157   93.2  38.0  4.00  4.8598   87  151\n",
      "1     48    1  21.6   87.00  183  103.2  70.0  3.00  3.8918   69   75\n",
      "2     72    2  30.5   93.00  156   93.6  41.0  4.00  4.6728   85  141\n",
      "3     24    1  25.3   84.00  198  131.4  40.0  5.00  4.8903   89  206\n",
      "4     50    1  23.0  101.00  192  125.4  52.0  4.00  4.2905   80  135\n",
      "5     23    1  22.6   89.00  139   64.8  61.0  2.00  4.1897   68   97\n",
      "6     36    2  22.0   90.00  160   99.6  50.0  3.00  3.9512   82  138\n",
      "7     66    2  26.2  114.00  255  185.0  56.0  4.55  4.2485   92   63\n",
      "8     60    2  32.1   83.00  179  119.4  42.0  4.00  4.4773   94  110\n",
      "9     29    1  30.0   85.00  180   93.4  43.0  4.00  5.3845   88  310\n",
      "10    22    1  18.6   97.00  114   57.6  46.0  2.00  3.9512   83  101\n",
      "11    56    2  28.0   85.00  184  144.8  32.0  6.00  3.5835   77   69\n",
      "12    53    1  23.7   92.00  186  109.2  62.0  3.00  4.3041   81  179\n",
      "13    50    2  26.2   97.00  186  105.4  49.0  4.00  5.0626   88  185\n",
      "14    61    1  24.0   91.00  202  115.4  72.0  3.00  4.2905   73  118\n",
      "15    34    2  24.7  118.00  254  184.2  39.0  7.00  5.0370   81  171\n",
      "16    47    1  30.3  109.00  207  100.2  70.0  3.00  5.2149   98  166\n",
      "17    68    2  27.5  111.00  214  147.0  39.0  5.00  4.9416   91  144\n",
      "18    38    1  25.4   84.00  162  103.0  42.0  4.00  4.4427   87   97\n",
      "19    41    1  24.7   83.00  187  108.2  60.0  3.00  4.5433   78  168\n",
      "20    35    1  21.1   82.00  156   87.8  50.0  3.00  4.5109   95   68\n",
      "21    25    2  24.3   95.00  162   98.6  54.0  3.00  3.8501   87   49\n",
      "22    25    1  26.0   92.00  187  120.4  56.0  3.00  3.9703   88   68\n",
      "23    61    2  32.0  103.67  210   85.2  35.0  6.00  6.1070  124  245\n",
      "24    31    1  29.7   88.00  167  103.4  48.0  4.00  4.3567   78  184\n",
      "25    30    2  25.2   83.00  178  118.4  34.0  5.00  4.8520   83  202\n",
      "26    19    1  19.2   87.00  124   54.0  57.0  2.00  4.1744   90  137\n",
      "27    42    1  31.9   83.00  158   87.6  53.0  3.00  4.4659  101   85\n",
      "28    63    1  24.4   73.00  160   91.4  48.0  3.00  4.6347   78  131\n",
      "29    67    2  25.8  113.00  158   54.2  64.0  2.00  5.2933  104  283\n",
      "..   ...  ...   ...     ...  ...    ...   ...   ...     ...  ...  ...\n",
      "412   69    1  34.3  113.00  200  123.8  54.0  4.00  4.7095  112  261\n",
      "413   34    1  26.3   87.00  197  120.0  63.0  3.00  4.2485   96  113\n",
      "414   71    2  27.0   93.33  269  190.2  41.0  6.56  5.2417   93  131\n",
      "415   47    1  27.2   80.00  208  145.6  38.0  6.00  4.8040   92  174\n",
      "416   41    1  33.8  123.33  187  127.0  45.0  4.16  4.3175  100  257\n",
      "417   34    1  33.0   73.00  178  114.6  51.0  3.49  4.1271   92   55\n",
      "418   51    1  24.1   87.00  261  175.6  69.0  4.00  4.4067   93   84\n",
      "419   43    1  21.3   79.00  141   78.8  53.0  3.00  3.8286   90   42\n",
      "420   55    1  23.0   94.67  190  137.6  38.0  5.00  4.2767  106  146\n",
      "421   59    2  27.9  101.00  218  144.2  38.0  6.00  5.1874   95  212\n",
      "422   27    2  33.6  110.00  246  156.6  57.0  4.00  5.0876   89  233\n",
      "423   51    2  22.7  103.00  217  162.4  30.0  7.00  4.8122   80   91\n",
      "424   49    2  27.4   89.00  177  113.0  37.0  5.00  4.9053   97  111\n",
      "425   27    1  22.6   71.00  116   43.4  56.0  2.00  4.4188   79  152\n",
      "426   57    2  23.2  107.33  231  159.4  41.0  5.63  5.0304  112  120\n",
      "427   39    2  26.9   93.00  136   75.4  48.0  3.00  4.1431   99   67\n",
      "428   62    2  34.6  120.00  215  129.2  43.0  5.00  5.3660  123  310\n",
      "429   37    1  23.3   88.00  223  142.0  65.0  3.40  4.3567   82   94\n",
      "430   46    1  21.1   80.00  205  144.4  42.0  5.00  4.5326   87  183\n",
      "431   68    2  23.5  101.00  162   85.4  59.0  3.00  4.4773   91   66\n",
      "432   51    1  31.5   93.00  231  144.0  49.0  4.70  5.2523  117  173\n",
      "433   41    1  20.8   86.00  223  128.2  83.0  3.00  4.0775   89   72\n",
      "434   53    1  26.5   97.00  193  122.4  58.0  3.00  4.1431   99   49\n",
      "435   45    1  24.2   83.00  177  118.4  45.0  4.00  4.2195   82   64\n",
      "436   33    1  19.5   80.00  171   85.4  75.0  2.00  3.9703   80   48\n",
      "437   60    2  28.2  112.00  185  113.8  42.0  4.00  4.9836   93  178\n",
      "438   47    2  24.9   75.00  225  166.0  42.0  5.00  4.4427  102  104\n",
      "439   60    2  24.9   99.67  162  106.6  43.0  3.77  4.1271   95  132\n",
      "440   36    1  30.0   95.00  201  125.2  42.0  4.79  5.1299   85  220\n",
      "441   36    1  19.6   71.00  250  133.2  97.0  3.00  4.5951   92   57\n",
      "\n",
      "[442 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.data','\\t')\n",
    "print(data)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sm9xTLRe_waF"
   },
   "source": [
    "### Training and Testing Data Sets\n",
    "\n",
    "b) Split the data set into training and testing data set with a 80:20 ratio.\n",
    "\n",
    "(Hint: What precautions must you take before you split the data set?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3vwkJem_waG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(data)\n",
    "train = data[0:354,:]\n",
    "test = data[354:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qfwzLcr_waJ"
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "c) Using linear regression, seek a model for the response of interest ($Y$), as a function of the baseline variables such as age, sex, body mass index, etc. Compute the training error and testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1565616648527,
     "user": {
      "displayName": "MALKAPURAM GANDLA SAI SREE",
      "photoUrl": "",
      "userId": "06629185457401699264"
     },
     "user_tz": -330
    },
    "id": "DvCRLsF-_waK",
    "outputId": "3e0434e8-0df9-4035-f2a0-fcdb685aced7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 2940.815513704523\n",
      "Testing Error: 2610.401561501811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(train[:,0:10],train[:,10])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predtr = reg.predict(train[:,0:10])\n",
    "predte = reg.predict(test[:,0:10])\n",
    "train_error = mean_squared_error(train[:,10],predtr)\n",
    "test_error = mean_squared_error(test[:,10],predte)\n",
    "print('Training Error:',train_error)\n",
    "print('Testing Error:',test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "d) Normalize the data set and perform linear regression again. Compute the training error and testing error. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1565616649829,
     "user": {
      "displayName": "MALKAPURAM GANDLA SAI SREE",
      "photoUrl": "",
      "userId": "06629185457401699264"
     },
     "user_tz": -330
    },
    "id": "1hO4CGs9_waO",
    "outputId": "d4dfda9a-e901-4b46-d8e6-0d4fca57820f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error Normalized: 0.48362342756694393\n",
      "Testing Error Normalized: 0.4292861434579788\n"
     ]
    }
   ],
   "source": [
    "# mean = np.mean(train[:,0:10],axis=0)\n",
    "# var = np.mean(((train[:,0:10] - mean)**2),axis=0)\n",
    "# std = np.sqrt(var)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "train_n = scale.fit_transform(train)\n",
    "test_n = scale.transform(test)\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(train_n[:,0:10],train_n[:,10])\n",
    "predtr_norm = reg2.predict(train_n[:,0:10])\n",
    "predte_norm = reg2.predict(test_n[:,0:10])\n",
    "train_mse_norm = mean_squared_error(train_n[:,10],predtr_norm)\n",
    "test_mse_norm = mean_squared_error(test_n[:,10],predte_norm)\n",
    "print('Training Error Normalized:',train_mse_norm)\n",
    "print('Testing Error Normalized:',test_mse_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wo1Xa-0bDZmq"
   },
   "source": [
    "### Feature Reduction\n",
    "\n",
    "e) Rank the features in order of importance (based on the study in d)). Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1565617372770,
     "user": {
      "displayName": "MALKAPURAM GANDLA SAI SREE",
      "photoUrl": "",
      "userId": "06629185457401699264"
     },
     "user_tz": -330
    },
    "id": "8NzU6I2RDiVK",
    "outputId": "98cdbe7e-29e2-438e-de5f-bd57419c2b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00879172 -0.13748946  0.34396646  0.19004288 -0.44228641  0.21568029\n",
      "  0.11974461  0.18928457  0.4155079   0.06303564]\n"
     ]
    }
   ],
   "source": [
    "print(reg2.coef_)\n",
    "# therefore going from highest to the lowest importance we get:\n",
    "# 1st is S1 (highest importance)\n",
    "# 2nd is S5\n",
    "# 3rd is BMI\n",
    "# 4th is S2\n",
    "# 5th is BP\n",
    "# 6th is S4\n",
    "# 7th is SEX\n",
    "# 8th is S3\n",
    "# 9th is S6\n",
    "# 10th is AGE (lowest importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "\n",
    "f) Repeat the exercise in d) with quadratic features. List the features you would add to the existing data set. Compute the training error and the testing error. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.6704713765072232\n",
      "Testing Error 0.6169251467027934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2)\n",
    "trainpoly = poly.fit_transform(train[:,0:10])\n",
    "testpoly = poly.transform(test[:,0:10])\n",
    "scale2 = StandardScaler()\n",
    "trainq = np.zeros((np.shape(trainpoly)[0],67))\n",
    "trainq[:,0:66] += trainpoly\n",
    "trainq[:,66]   += train[:,10]\n",
    "testq = np.zeros((np.shape(testpoly)[0],67))\n",
    "testq[:,0:66] += testpoly\n",
    "testq[:,66]  += test[:,10]\n",
    "trainq = scale2.fit_transform(trainq)\n",
    "testq = scale2.transform(testq)\n",
    "regq = LinearRegression()\n",
    "regq.fit(trainq[:,0:10],trainq[:,10])\n",
    "predtrq = regq.predict(trainq[:,0:10])\n",
    "predteq = regq.predict(testq[:,0:10])\n",
    "msetrq = mean_squared_error(trainq[:,10],predtrq)\n",
    "mseteq = mean_squared_error(testq[:,10],predteq)\n",
    "print('Training Error:',msetrq)\n",
    "print('Testing Error',mseteq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise Part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
